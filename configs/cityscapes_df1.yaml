DEVICE          : cuda              # device used for training and evaluation (cpu, cuda, cuda0, cuda1, ...)
SAVE_DIR        : 'output_cityscapes_df1'         # output folder name used for saving the model, logs and inference results

MODEL:                                    
  NAME          : SFNet                                           # name of the model you are using
  BACKBONE      : DFNet-1                                                 # model variant
  PRETRAINED    : './pretrained/df1_imagenet.pth'              # backbone model's weight 

DATASET:
  NAME          : CityScapes                                          # dataset name to be trained with (camvid, cityscapes, ade20k)
  ROOT          : '/input/sunil/dataset/Cityscapes/'                                   # dataset root path
  IGNORE_LABEL  : 255

TRAIN:
  IMAGE_SIZE    : [1024, 1024]    # training image size in (h, w)
  BATCH_SIZE    : 2               # batch size used to train
  EPOCHS        : 432             # number of epochs to train
  EVAL_INTERVAL : 10              # evaluation interval during training
  AMP           : true           # use AMP in training
  DDP           : true           # use DDP training
  NUM_GPUs      : 4           # use DDP training

LOSS:
  NAME          : OhemCrossEntropy          # loss function name (ohemce, ce, dice)
  CLS_WEIGHTS   : false            # use class weights in loss calculation

OPTIMIZER:
  NAME          : sgd           # optimizer name
  LR            : 0.01           # initial learning rate used in optimizer
  WEIGHT_DECAY  : 0.0005            # decay rate used in optimizer 

SCHEDULER:
  NAME          : polylr    # scheduler name
  POWER         : 0.9             # scheduler power
  WARMUP        : 10              # warmup epochs used in scheduler
  WARMUP_RATIO  : 0.1             # warmup ratio
  

EVAL:
  MODEL_PATH    : 'output/segformer_B0_citycapes.pth'     # trained model file path
  IMAGE_SIZE    : [1024, 1024]                            # evaluation image size in (h, w)                       
  MSF: 
    ENABLE      : false                                   # multi-scale and flip evaluation  
    FLIP        : false                                    # use flip in evaluation  
    SCALES      : [1.0]       # scales used in MSF evaluation                


TEST:
  MODEL_PATH    : 'checkpoints/pretrained/ddrnet/ddrnet_23_city.pth'    # trained model file path
  FILE          : 'assests/cityscapes'                    # filename or foldername 
  IMAGE_SIZE    : [1024, 1024]                            # inference image size in (h, w)
  OVERLAY       : true                                    # save the overlay result (image_alpha+label_alpha)